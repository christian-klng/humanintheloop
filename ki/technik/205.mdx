---
title: 'Mit Golfbällen jonglieren'
description: 'Einige, besonders ältere Modelle scheitern schon an einfachen Logik-Fragen. Probiere einmal den folgenden Prompt aus:

Ein Jongleur hat 16 Bälle. Die eine Hälfte der Bälle sind Golfbälle, die Hälfte der Golfbälle sind blau. Wie viele blaue Golfbälle hat der Jongleur?

Für Große Sprachmodelle ist Logik also nicht so einfach wie für uns Menschen. Ein kleiner Trick kann aber helfen, das auf das korrekte Ergebnis zu kommen.

Ergänze den System-Prompt: Denke Schritt für Schritt!

Alternativ: Erkläre mir zunächst den Lösungsweg, bevor du mir das Ergebnis nennst.'
sidebarTitle: 'Zero-Shot Chain-of-Thought (CoT)'
---

## Beispiel

```markdown icon="markdown" wrap
Prompt: „Frage: Wenn ein Zug 60 km/h fährt und 2 Stunden unterwegs ist, wie weit fährt er? Bitte denke Schritt für Schritt.“
```

## Bewertung

```markdown icon="markdown" wrap
Prüfe, ob die Aufforderung verlangt, den Gedankengang in Schritten darzustellen.
```

## Zero-Shot Chain-of-Thought (CoT)
„Chain-of-thought prompting enables complex reasoning by generating intermediate steps before the final answer“ (Wei et al., 2022, Chain-of-Thought Prompting Elicits Reasoning in Large Language Models). Kurz: Statt sofort zu antworten, wird der Lösungsweg Schritt für Schritt erklärt.